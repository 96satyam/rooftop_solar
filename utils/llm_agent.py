import os
from openai import OpenAI
from dotenv import load_dotenv

# Load environment variables from .env file
load_dotenv()
# Retrieve OpenAI API key from environment variables
api_key = os.getenv("OPENAI_API_KEY")

# Initialize OpenAI client with the retrieved API key
client = OpenAI(api_key=api_key)

def get_llm_response(prompt: str) -> str:
    """
    Sends a prompt to the OpenAI chat model and returns the generated response.
    Parameters:
        prompt (str): The input prompt to send to the model.
    Returns:
        str: The response generated by the model.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[
                {
                    "role": "system",
                    "content": (
                    "You are a solar installation expert who replies with detailed, numbered recommendations. "
                    "Always follow the format: panel type, panel count, tilt/orientation, subsidies, extra advice."
                ),
                },
                {"role": "user", "content": prompt}
            ],
            temperature=0.65  
        )

        return response.choices[0].message.content

    except Exception as e:
        raise Exception(f"OpenAI API error: {e}")